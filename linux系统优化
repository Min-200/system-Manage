作为一名linux系统管理员，最主要的工作是优化系统配置，使应用在系统上以最优的状态运行，但是由于硬件问题、软件问题、网络环境等的复杂性 和多变性，导致对系统的优化变得异常复杂，如何定位性能问题出在哪个方面，是性能优化的一大难题， 本章从系统入手，重点讲述由于系统软、硬件配置不当可能造成的性能问题，并且给出了检测系统故障和优化性能的一般方法和流程。
1 cpu性能评估
 Cpu是影响Linux性能的主要因素之一，下面先介绍几个查看CPU性能的命令。
1.1 vmstat命令
该命令可以显示关于系统各种资源之间相关性能的简要信息，这里我们主要用它来看CPU的一个负载情况。
下面是vmstat命令在某个系统的输出结果：

点击(此处)折叠或打开
[root@node1 ~]# vmstat 2 3
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
r b swpd free buff cache si so bi bo in cs us sy id wa st
0 0 0 162240 8304 67032 0 0 13 21 1007 23 0 1 98 0 0
0 0 0 162240 8304 67032 0 0 1 0 1010 20 0 1 100 0 0
0 0 0 162240 8304 67032 0 0 1 1 1009 18 0 1 99 0 0

对上面每项的输出解释如下：
 procs
 r列表示运行和等待cpu时间片的进程数，这个值如果长期大于系统CPU的个数，说明CPU不足，需要增加CPU。
 b列表示在等待资源的进程数，比如正在等待I/O、或者内存交换等。
 memory
 swpd列表示切换到内存交换区的内存数量（以k为单位）。如果swpd的值不为0，或者比较大，只要si、so的值长期为0，这种情况下一般不用担心，不会影响系统性能。
 free列表示当前空闲的物理内存数量（以k为单位）
 buff列表示buffers cache的内存数量，一般对块设备的读写才需要缓冲。 
 cache列表示page cached的内存数量，一般作为文件系统cached，频繁访问的文件都会被cached，如果cache值较大，说明cached的文件数较多，如果此时IO中bi比较小，说明文件系统效率比较好。
 swap
 si列表示由磁盘调入内存，也就是内存进入内存交换区的数量。
 so列表示由内存调入磁盘，也就是内存交换区进入内存的数量。 
一般情况下，si、so的值都为0，如果si、so的值长期不为0，则表示系统内存不足。需要增加系统内存。
 IO项显示磁盘读写状况
 Bi列表示从块设备读入数据的总量（即读磁盘）（每秒kb）。
 Bo列表示写入到块设备的数据总量（即写磁盘）（每秒kb）
这里我们设置的bi+bo参考值为1000，如果超过1000，而且wa值较大，则表示系统磁盘IO有问题，应该考虑提高磁盘的读写性能。
 system 显示采集间隔内发生的中断数
 in列表示在某一时间间隔中观测到的每秒设备中断数。
 cs列表示每秒产生的上下文切换次数。
上面这2个值越大，会看到由内核消耗的CPU时间会越多。
 CPU项显示了CPU的使用状态，此列是我们关注的重点。
 us列显示了用户进程消耗的CPU 时间百分比。us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，就需要考虑优化程序或算法。
 sy列显示了内核进程消耗的CPU时间百分比。Sy的值较高时，说明内核消耗的CPU资源很多。
根据经验，us+sy的参考值为80%，如果us+sy大于 80%说明可能存在CPU资源不足。
 id 列显示了CPU处在空闲状态的时间百分比。
 wa列显示了IO等待所占用的CPU时间百分比。wa值越高，说明IO等待越严重，根据经验，wa的参考值为20%，如果wa超过20%，说明IO等待严重，引起IO等待的原因可能是磁盘大量随机读写造成的，也可能是磁盘或者磁盘控制器的带宽瓶颈造成的（主要是块操作）。
综上所述，在对CPU的评估中，需要重点注意的是procs项r列的值和CPU项中us、sy和id列的值。
1.2  sar命令
检查CPU性能的第二个工具是sar，sar功能很强大，可以对系统的每个方面进行单独的统计，但是使用sar命令会增加系统开销，不过这些开销是可以评估的，对系统的统计结果不会有很大影响。
下面是sar命令对某个系统的CPU统计输出：

点击(此处)折叠或打开
[root@webserver ~]# sar -u 3 5
Linux 2.6.9-42.ELsmp (webserver) 11/28/2008 _i686_ (8 CPU)
11:41:24 AM CPU %user %nice %system %iowait %steal %idle
11:41:27 AM all 0.88 0.00 0.29 0.00 0.00 98.83
11:41:30 AM all 0.13 0.00 0.17 0.21 0.00 99.50
11:41:33 AM all 0.04 0.00 0.04 0.00 0.00 99.92
11:41:36 AM all 0.29 0.00 0.13 0.00 0.00 99.58
11:41:39 AM all 0.38 0.00 0.17 0.04 0.00 99.41
Average: all 0.34 0.00 0.16 0.05 0.00 99.45

对上面每项的输出解释如下：
 %user列显示了用户进程消耗的CPU 时间百分比。
 %nice列显示了运行正常进程所消耗的CPU 时间百分比。
 %system列显示了系统进程消耗的CPU时间百分比。
 %iowait列显示了IO等待所占用的CPU时间百分比
 %steal列显示了在内存相对紧张的环境下pagein强制对不同的页面进行的steal操作 。
 %idle列显示了CPU处在空闲状态的时间百分比。
 这个输出是对系统整体CPU使用状况的统计，每项的输出都非常直观，并且最后一行Average是个汇总行，是上面统计信息的一个平均值。
 需要注意的一点是：第一行的统计信息中包含了sar本身的统计消耗，所以%user列的值会偏高一点，不过，这不会对统计结果产生多大影响。
 在一个多CPU的系统中，如果程序使用了单线程，会出现这么一个现象，CPU的整体使用率不高，但是系统应用却响应缓慢，这可能是由于程序使用单线程的原因，单线程只使用一个CPU，导致这个CPU占用率为100%，无法处理其它请求，而其它的CPU却闲置，这就导致 了整体CPU使用率不高，而应用缓慢 现象的发生 。
 针对这个问题，可以对系统的每个CPU分开查询，统计每个CPU的使用情况：

点击(此处)折叠或打开
[root@webserver ~]# sar -P 0 3 5
Linux 2.6.9-42.ELsmp (webserver) 11/29/2008 _i686_ (8 CPU)
06:29:33 PM CPU %user %nice %system %iowait %steal %idle
06:29:36 PM 0 3.00 0.00 0.33 0.00 0.00 96.67
06:29:39 PM 0 0.67 0.00 0.33 0.00 0.00 99.00
06:29:42 PM 0 0.00 0.00 0.33 0.00 0.00 99.67
06:29:45 PM 0 0.67 0.00 0.33 0.00 0.00 99.00
06:29:48 PM 0 1.00 0.00 0.33 0.33 0.00 98.34
Average: 0 1.07 0.00 0.33 0.07 0.00 98.53
这个输出是对系统的第一颗CPU的信息统计，需要注意的是，sar中对CPU的计数是从0开始的，因此，“sar -P 0 3 5”表示对系统的第一颗CPU进行信息统计，“sar -P 4 3 5”则表示对系统的第五颗CPU进行统计。依次类推。可以看出，上面的系统有八颗CPU。
1.3 iostat命令
 iostat指令主要用于统计磁盘IO状态，但是也能查看CPU的使用信息，它的局限性是只能显示系统所有CPU的平均信息，看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# iostat -c
Linux 2.6.9-42.ELsmp (webserver) 11/29/2008 _i686_ (8 CPU)
avg-cpu: %user %nice %system %iowait %steal %idle
2.52 0.00 0.30 0.24 0.00 96.96
 在这里，我们使用了“-c”参数，只显示系统CPU的统计信息，输出中每项代表的含义与sar命令的输出项完全相同，不再详述。
1.4 uptime命令
 uptime是监控系统性能最常用的一个命令，主要用来统计系统当前的运行状况，输出的信息依次为：系统现在的时间、系统从上次开机到现在运行了多长时间、系统目前有多少登陆用户、系统在一分钟内、五分钟内、十五分钟内的平均负载。看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# uptime
18:52:11 up 27 days, 19:44, 2 users, load average: 0.12, 0.08, 0.08

这里需要注意的是load average这个输出值，这三个值的大小一般不能大于系统CPU的个数，例如，本输出中系统有8个CPU,如果load average的三个值长期大于8时，说明CPU很繁忙，负载很高，可能会影响系统性能，但是偶尔大于8时，倒不用担心，一般不会影响系统性能。相反，如果load average的输出值小于CPU的个数，则表示CPU还有空闲的时间片，比如本例中的输出，CPU是非常空闲的。
1.5 本节小结
上面介绍了检查CPU使用状况的四个命令，通过这些命令需要了解的是：系统CPU是否出现性能瓶颈，也就是说，以上这些命令只能查看CPU是否繁忙，负载是否过大，但是无法知道CPU为何负载过大，因而，判断系统CPU出现问题后，要结合top、ps等命令进一步检查是由那些进程导致CPU负载过大的。引起CPU资源紧缺的原因可能是应用程序不合理造成的，也可能是硬件资源匮乏引起的，所以，要具体问题具体分析，或者优化应用程序，或者增加系统CPU资源。
2 内存性能评估
内存的管理和优化是系统性能优化的一个重要部分，内存资源的充足与否直接影响应用系统的使用性能，在进行内存优化之前，一定要熟悉linux的内存管理机制，这一点我们在前面的章节已经有深入讲述，本节的重点是如何通过系统命令监控linux系统的内存使用状况。
2.1 free 命令
free是监控linux内存使用状况最常用的指令，看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# free -m
total used free shared buffers cached
Mem: 8111 7185 925 0 243 6299
-/+ buffers/cache: 643 7468
Swap: 8189 0 8189
  “free –m”表示以M为单位查看内存使用情况，在这个输出中，我们重点关注的应该是free列与cached列的输出值，由输出可知，此系统共8G内存，系统空闲内存还有925M，其中，Buffer Cache占用了243M，Page Cache占用了6299M，由此可知系统缓存了很多的文件和目录，而对于应用程序来说，可以使用的内存还有7468M，当然这个7468M包含了Buffer Cache和Page Cache的值。在swap项可以看出，交换分区还未使用。所以从应用的角度来说，此系统内存资源还非常充足。 
  一般有这样一个经验公式：应用程序可用内存/系统物理内存>70%时，表示系统内存资源非常充足，不影响系统性能，应用程序可用内存/系统物理内存<20%时，表示系统内存资源紧缺，需要增加系统内存，20%<应用程序可用内存/系统物理内存<70%时，表示系统内存资源基本能满足应用需求，暂时不影响系统性能。
  free命令还可以适时的监控内存的使用状况，使用“-s”参数可以在指定的时间段内不间断的监控内存的使用情况：

点击(此处)折叠或打开
[root@webserver ~]# free -b -s 5
total used free shared buffers cached
Mem: 8505901056 7528706048 977195008 0 260112384 6601158656
-/+ buffers/cache: 667435008 7838466048
Swap: 8587149312 163840 8586985472
total used free shared buffers cached
Mem: 8505901056 7526936576 978964480 0 260128768 6601142272
-/+ buffers/cache: 665665536 7840235520
Swap: 8587149312 163840 8586985472
total used free shared buffers cached
Mem: 8505901056 7523987456 981913600 0 260141056 6601129984
-/+ buffers/cache: 662716416 7843184640
Swap: 8587149312 163840 8586985472
  其中，“-b”表示以千字节(也就是1024字节为单位)来显示内存使用情况。
2.2 通过watch与free相结合动态监控内存状况
 watch是一个非常有用的命令，几乎每个linux发行版都带有这个工具，通过watch，可以动态的监控命令的运行结果，省去手动执行的麻烦。
  可以在watch后面跟上需要运行的命令，watch就会自动重复去运行这个命令，默认是2秒钟执行一次，并把执行的结果更新在屏幕上。例如：

点击(此处)折叠或打开
[root@webserver ~]# watch -n 3 -d free
Every 3.0s: free Sun Nov 30 16:23:20 2008
total used free shared buffers cached
Mem: 8306544 7349548 956996 0 203296 6500024
-/+ buffers/cache: 646228 7660316
Swap: 8385888 160 8385728
 
其中，“-n”指定重复执行的时间，“-d”表示高亮显示变动。
2.3 vmstat命令监控内存
vmstat命令在监控系统内存方面功能强大，请看下面的一个输出：

点击(此处)折叠或打开
procs -----------memory---------- ---swap-- -----io---- --system-- ----cpu----
r b swpd free buff cache si so bi bo in cs us sy id wa
0 0 906440 22796 155616 1325496 340 180 2 4 1 4 80 0 10 10
0 0 906440 42796 155616 1325496 320 289 0 54 1095 287 70 15 0 15
0 0 906440 42884 155624 1325748 236 387 2 102 1064 276 78 2 5 15

对于内存的监控，在vmstat中重点关注的是swpd、si和so行，从这个输出可以看出，此系统内存资源紧缺，swpd占用了900M左右内存，si和so占用很大，而由于系统内存的紧缺，导致出现15%左右的系统等待，此时增加系统的内存是必须要做的。
2.4 sar -r命令组合
sar命令也可以监控linux的内存使用状况，可以通过“sar –r”组合查看系统内存和交换空间的使用率。请看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# sar -r 2 3
Linux 2.6.9-42.ELsmp (webserver) 11/30/2008 _i686_ (8 CPU)
09:57:33 PM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit
09:57:35 PM 897988 7408556 89.19 249428 6496532 786556 4.71
09:57:37 PM 898564 7407980 89.18 249428 6496532 784276 4.70
09:57:39 PM 899196 7407348 89.17 249440 6496520 782132 4.69
Average: 898583 7407961 89.18 249432 6496528 784321 4.70

其中：
Kbmemfree表示空闲物理内存大小，kbmemused表示已使用的物理内存空间大小，%memused表示已使用内存占总内存大小的百分比，kbbuffers和kbcached分别表示Buffer Cache和Page Cache的大小，kbcommit和%commit分别表示应用程序当前使用的内存大小和使用百分比。
可以看出sar的输出其实与free的输出完全对应，不过sar更加人性化，不但给出了内存使用量，还给出了内存使用的百分比以及统计的平均值。从%commit项可知，此系统目前内存资源充足。
2.5 本节小结
 上面介绍了内存监控常用的几个指令以及一些经验规则，其实现在的系统在内存方面出现的瓶颈已经很少，因为内存价格很低，充足的内存已经完全能满足应用程序和系统本身的需要，如果系统在内存方面出现瓶颈，很大的可能是应用程序本身的问题造成的。
3 磁盘I/O性能评估
 在对磁盘I/O性能做评估之前，必须知道的几个方面是：
 熟悉RAID存储方式，可以根据应用的不同，选择不同的RAID方式，例如，如果一个应用经常有大量的读操作，可以选择RAID5方式构建磁盘阵列存储数据，如果应用有大量的、频繁的写操作，可以选择raid0存取方式，如果应用对数据安全要求很高，同时对读写也有要求的话，可以考虑raid01存取方式等等。
 尽可能用内存的读写代替直接磁盘I/O，使频繁访问的文件或数据放入内存中进行操作处理，因为内存读写操作比直接磁盘读写的效率要高千倍。
 将经常进行读写的文件与长期不变的文件独立出来，分别放置到不同的磁盘设备上。
 对于写操作频繁的数据，可以考虑使用裸设备代替文件系统。这里简要讲述下文件系统与裸设备的对比：
使用裸设备的优点有：
 数据可以直接读写，不需要经过操作系统级的缓存，节省了内存资源，避免了内存资源争用。
 避免了文件系统级的维护开销，比如文件系统需要维护超级块、I-node等。
 避免了操作系统的cache预读功能，减少了I/O请求。
使用裸设备的缺点是：
 数据管理、空间管理不灵活，需要很专业的人来操作。
其实裸设备的优点就是文件系统的缺点，反之也是如此，这就需要我们做出合理的规划和衡量，根据应用的需求，做出对应的策略。
下面接着介绍对磁盘IO的评估标准。
3.1 sar -d命令组合
 通过“sar –d”组合，可以对系统的磁盘IO做一个基本的统计，请看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# sar -d 2 3
Linux 2.6.9-42.ELsmp (webserver) 11/30/2008 _i686_ (8 CPU)
11:09:33 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util
11:09:35 PM dev8-0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
11:09:35 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util
11:09:37 PM dev8-0 1.00 0.00 12.00 12.00 0.00 0.00 0.00 0.00
11:09:37 PM DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util
11:09:39 PM dev8-0 1.99 0.00 47.76 24.00 0.00 0.50 0.25 0.05
Average: DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util
Average: dev8-0 1.00 0.00 19.97 20.00 0.00 0.33 0.17 0.02
 
 对上面每项的输出解释如下：
 DEV表示磁盘设备名称。
 tps表示每秒到物理磁盘的传送数，也就是每秒的I/O流量。一个传送就是一个I/O请求，多个逻辑请求可以被合并为一个物理I/O请求。
 rd_sec/s表示每秒从设备读取的扇区数（1扇区=512字节）。
 wr_sec/s表示每秒写入设备的扇区数目。
 avgrq-sz表示平均每次设备I/O操作的数据大小（以扇区为单位）。
 avgqu-sz表示平均I/O队列长度。
 await表示平均每次设备I/O操作的等待时间（以毫秒为单位）。
 svctm表示平均每次设备I/O操作的服务时间（以毫秒为单位）。
 %util表示一秒中有百分之几的时间用于I/O操作。
Linux中I/O请求系统与现实生活中超市购物排队系统有很多类似的地方，通过对超市购物排队系统的理解，可以很快掌握linux中I/O运行机制。比如：
avgrq-sz类似与超市排队中每人所买东西的多少。
avgqu-sz类似与超市排队中单位时间内平均排队的人数。
await类似与超市排队中每人的等待时间。
svctm类似与超市排队中收银员的收款速度。
 %util类似与超市收银台前有人排队的时间比例。
对以磁盘IO性能，一般有如下评判标准：
 正常情况下svctm应该是小于await值的，而svctm的大小和磁盘性能有关，CPU、内存的负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。
 await值的大小一般取决与svctm的值和I/O队列长度以及I/O请求模式，如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。
 %util项的值也是衡量磁盘I/O的一个重要指标，如果%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷的在工作，该磁盘可能存在瓶颈。长期下去，势必影响系统的性能，可以通过优化程序或者通过更换更高、更快的磁盘来解决此问题。
3.2 iostat –d命令组合
 通过“iostat –d”命令组合也可以查看系统磁盘的使用状况，请看如下输出：


点击(此处)折叠或打开
[root@webserver ~]# iostat -d 2 3
Linux 2.6.9-42.ELsmp (webserver) 12/01/2008 _i686_ (8 CPU)
Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtn
sda 1.87 2.58 114.12 6479462 286537372
Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtn
sda 0.00 0.00 0.00 0 0
Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtn
sda 1.00 0.00 12.00 0 24
 
 对上面每项的输出解释如下：
 Blk_read/s表示每秒读取的数据块数。
 Blk_wrtn/s表示每秒写入的数据块数。
 Blk_read表示读取的所有块数
 Blk_wrtn表示写入的所有块数。
这里需要注意的一点是：上面输出的第一项是系统从启动以来到统计时的所有传输信息，从第二次输出的数据才代表在检测的时间段内系统的传输值。
可以通过Blk_read/s和Blk_wrtn/s的值对磁盘的读写性能有一个基本的了解，如果Blk_wrtn/s值很大，表示磁盘的写操作很频繁，可以考虑优化磁盘或者优化程序，如果Blk_read/s值很大，表示磁盘直接读取操作很多，可以将读取的数据放入内存中进行操作。对于这两个选项的值没有一个固定的大小，根据系统应用的不同，会有不同的值，但是有一个规则还是可以遵循的：长期的、超大的数据读写，肯定是不正常的，这种情况一定会影响系统性能。
“iostat –x”组合还提供了对每个磁盘的单独统计，如果不指定磁盘，默认是对所有磁盘进行统计，请看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# iostat -x /dev/sda 2 3
Linux 2.6.9-42.ELsmp (webserver) 12/01/2008 _i686_ (8 CPU)
avg-cpu: %user %nice %system %iowait %steal %idle
2.45 0.00 0.30 0.24 0.00 97.03
Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s avgrq-sz avgqu-sz await svctm %util
sda 0.01 12.48 0.10 1.78 2.58 114.03 62.33 0.07 38.39 1.30 0.24
avg-cpu: %user %nice %system %iowait %steal %idle
3.97 0.00 1.83 8.19 0.00 86.14
Device:rrqm/s wrqm/s r/s w/s rsec/s wsec/s avgrq-sz avgqu-sz await svctm %util
sda 0.00 195.00 0.00 18.00 0.00 1704.00 94.67 0.04 2.50 0.11 0.20
avg-cpu: %user %nice %system %iowait %steal %idle
4.04 0.00 1.83 8.01 0.00 86.18
Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s avgrq-sz avgqu-sz await svctm %util
sda 0.00 4.50 0.00 7.00 0.00 92.00 13.14 0.01 0.79 0.14 0.10

这个输出基本与“sar –d”相同，需要说明的几个选项的含义为：
 rrqm/s表示每秒进行merged的读操作数目。
 wrqm/s表示每秒进行 merge 的写操作数目。
 r/s表示每秒完成读I/O设备的次数。
 w/s表示每秒完成写I/O设备的次数。
 rsec/s表示每秒读取的扇区数。
 wsec/s表示每秒写入的扇区数。
3.3 vmstat –d组合
 通过“vmstat –d”组合也可以查看磁盘的统计数据，情况下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# vmstat -d 3 2|grep sda
disk- ------------reads------------ ------------writes----------- -----IO------
total merged sectors ms total merged sectors ms cur sec
sda 239588 29282 6481862 1044442 4538678 32387680 295410812 186025580 0 6179
disk- ------------reads------------ ------------writes----------- -----IO------
total merged sectors ms total merged sectors ms cur sec
sda 239588 29282 6481862 1044442 4538680 32387690 295410908 186025581 0 6179

这个输出显示了磁盘的reads、writes和IO的使用状况。
3.4 本节小结
 上面主要讲解了对磁盘I/O的性能评估，其实衡量磁盘I/O好坏是多方面的，有应用程序本身的，也有硬件设计上的，还有系统自身配置的问题等，要解决I/O的瓶颈，关键是要提高I/O子系统的执行效率。例如，首要要从应用程序上对磁盘读写进行优化，能够放到内存执行的操作，尽量不要放到磁盘，同时对磁盘存储方式进行合理规划，选择适合自己的RAID存取方式，最后，在系统级别上，可以选择适合自身应用的文件系统，必要时使用裸设备提高读写性能。
4 网络性能评估
 网络性能的好坏直接影响应用程序对外提供服务的稳定性和可靠性，监控网络性能，可以从以下几个方面进行管理和优化。
4.1 通过ping命令检测网络的连通性
 如果发现网络反应 缓慢，或者连接中断，可以通过ping来测试网络的连通情况，请看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# ping 10.10.1.254
PING 10.10.1.254 (10.10.1.254) 56(84) bytes of data.
64 bytes from 10.10.1.254: icmp_seq=0 ttl=64 time=0.235 ms
64 bytes from 10.10.1.254: icmp_seq=1 ttl=64 time=0.164 ms
64 bytes from 10.10.1.254: icmp_seq=2 ttl=64 time=0.210 ms
64 bytes from 10.10.1.254: icmp_seq=3 ttl=64 time=0.178 ms
64 bytes from 10.10.1.254: icmp_seq=4 ttl=64 time=0.525 ms
64 bytes from 10.10.1.254: icmp_seq=5 ttl=64 time=0.571 ms
64 bytes from 10.10.1.254: icmp_seq=6 ttl=64 time=0.220 ms
--- 10.10.1.254 ping statistics ---
7 packets transmitted, 7 received, 0% packet loss, time 6000ms
rtt min/avg/max/mdev = 0.164/0.300/0.571/0.159 ms, pipe 2

 
 在这个输出中，time值显示了两台主机之间的网络延时情况，如果此值很大，则表示网络的延时很大，单位为毫秒。在这个输出的最后，是对上面输出信息的一个总结，packet loss表示网络的丢包率，此值越小，表示网络的质量越高。
4.2 通过netstat –i组合检测网络接口状况
netstat命令提供了网络接口的详细信息，请看下面的输出：

点击(此处)折叠或打开
[root@webserver ~]# netstat -i
Kernel Interface table
Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg
eth0 1500 0 1313129253 0 0 0 1320686497 0 0 0 BMRU
eth1 1500 0 494902025 0 0 0 292358810 0 0 0 BMRU
lo 16436 0 41901601 0 0 0 41901601 0 0 0 LRU
 
 对上面每项的输出解释如下：
 Iface表示网络设备的接口名称。
 MTU表示最大传输单元，单位字节。
 RX-OK/TX-OK表示已经准确无误的接收/发送了多少数据包。
 RX-ERR/TX-ERR表示接收/发送数据包时产生了多少错误。
 RX-DRP/TX-DRP表示接收/发送数据包时丢弃了多少数据包。
 RX-OVR/TX-OVR表示由于误差而遗失了多少数据包。
 Flg表示接口标记，其中：
 L：表示该接口是个回环设备。
 B：表示设置了广播地址。
 M：表示接收所有数据包。
 R：表示接口正在运行。
 U：表示接口处于活动状态。
 O：表示在该接口上禁用arp。
 P：表示一个点到点的连接。
正常情况下，RX-ERR/TX-ERR、RX-DRP/TX-DRP和RX-OVR/TX-OVR的值都应该为0，如果这几个选项的值不为0，并且很大，那么网络质量肯定有问题，网络传输性能也一定会下降。
当网络传输存在问题是，可以检测网卡设备是否存在故障，如果可能，可以升级为千兆网卡或者光纤网络，还可以检查网络部署环境是否合理。
4.3 通过netstat –r组合检测系统的路由表信息
 在网络不通，或者网络异常时，首先想到的就是检查系统的路由表信息，“netstat –r”的输出结果与route命令的输出完全相同，请看下面的一个实例：

点击(此处)折叠或打开
[root@webserver ~]# netstat -r
Kernel IP routing table
Destination Gateway Genmask Flags MSS Window irtt Iface
10.10.1.0 * 255.255.255.0 U 0 0 0 eth0
192.168.200.0 * 255.255.255.0 U 0 0 0 eth1
169.254.0.0 * 255.255.0.0 U 0 0 0 eth1
default 10.10.1.254 0.0.0.0 UG 0 0 0 eth0
 
 关于输出中每项的具体含义，已经在前面章节进行过详细介绍，这里不再多讲，这里我们重点关注的是default行对应的值，default项表示系统的默认路由，对应的网络接口为eth0。
4.4 通过sar –n组合显示系统的网络运行状态
 sar提供四种不同的选项来显示网络统计信息，通过“-n”选项可以指定4个不同类型的开关：DEV、EDEV、SOCK和FULL。DEV显示网络接口信息，EDEV显示关于网络错误的统计数据，SOCK显示套接字信息，FULL显示所有三个开关。请看下面的一个输出：

点击(此处)折叠或打开
[root@webserver ~]# sar -n DEV 2 3
Linux 2.6.9-42.ELsmp (webserver) 12/01/2008 _i686_ (8 CPU)
02:22:31 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s
02:22:33 PM lo 31.34 31.34 37.53 37.53 0.00 0.00 0.00
02:22:33 PM eth0 199.50 279.60 17.29 344.12 0.00 0.00 0.00
02:22:33 PM eth1 5.47 4.98 7.03 0.36 0.00 0.00 0.00
02:22:33 PM sit0 0.00 0.00 0.00 0.00 0.00 0.00 0.00
02:22:33 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s
02:22:35 PM lo 67.66 67.66 74.34 74.34 0.00 0.00 0.00
02:22:35 PM eth0 159.70 222.39 19.74 217.16 0.00 0.00 0.00
02:22:35 PM eth1 3.48 4.48 0.44 0.51 0.00 0.00 0.00
02:22:35 PM sit0 0.00 0.00 0.00 0.00 0.00 0.00 0.00
02:22:35 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s
02:22:37 PM lo 4.52 4.52 9.25 9.25 0.00 0.00 0.00
02:22:37 PM eth0 102.51 133.67 20.67 116.14 0.00 0.00 0.00
02:22:37 PM eth1 27.14 67.34 2.42 89.26 0.00 0.00 0.00
02:22:37 PM sit0 0.00 0.00 0.00 0.00 0.00 0.00 0.00
Average: IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s
Average: lo 34.61 34.61 40.48 40.48 0.00 0.00 0.00
Average: eth0 154.08 212.15 19.23 226.17 0.00 0.00 0.00
Average: eth1 11.98 25.46 3.30 29.85 0.00 0.00 0.00
Average: sit0 0.00 0.00 0.00 0.00 0.00 0.00 0.00
 
对上面每项的输出解释如下：
 IFACE表示网络接口设备。
 rxpck/s表示每秒钟接收的数据包大小。
 txpck/s表示每秒钟发送的数据包大小。
 rxkB/s表示每秒钟接收的字节数。
 txkB/s表示每秒钟发送的字节数。
 rxcmp/s表示每秒钟接收的压缩数据包。
 txcmp/s表示每秒钟发送的压缩数据包。
 rxmcst/s表示每秒钟接收的多播数据包。
通过“sar –n”的输出，可以清楚的显示网络接口发送、接收数据的统计信息。此外还可以通过“sar -n EDEV 2 3”来统计网络错误信息等。
4.5 小结
本节通过几个常用的网络命令介绍了对网络性能的评估，事实上，网络问题是简单而且容易处理的，只要我们根据上面给出的命令，一般都能迅速定位问题。解决问题的方法一般是增加网络带宽，或者优化网络部署环境。
 除了上面介绍的几个命令外，排查网络问题经常用到的命令还有traceroute，主要用于跟踪数据包的传输路径，还有nslookup命令，主要用于判断DNS解析信息。# system-Manage
